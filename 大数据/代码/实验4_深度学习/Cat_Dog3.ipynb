{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b257238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef8e53",
   "metadata": {},
   "source": [
    "![](picture/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4cde5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRN(nn.Module):\n",
    "    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=True):\n",
    "        super(LRN, self).__init__()\n",
    "        self.ACROSS_CHANNELS = ACROSS_CHANNELS\n",
    "        if ACROSS_CHANNELS:\n",
    "            self.average=nn.AvgPool3d(kernel_size=(local_size, 1, 1),\n",
    "                    stride=1,\n",
    "                    padding=(int((local_size-1.0)/2), 0, 0))\n",
    "        else:\n",
    "            self.average=nn.AvgPool2d(kernel_size=local_size,\n",
    "                    stride=1,\n",
    "                    padding=int((local_size-1.0)/2))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.ACROSS_CHANNELS:\n",
    "            div = x.pow(2).unsqueeze(1)\n",
    "            div = self.average(div).squeeze(1)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        else:\n",
    "            div = x.pow(2)\n",
    "            div = self.average(div)\n",
    "            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
    "        x = x.div(div)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d289054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "\n",
    "        #conv\n",
    "        self.conv1 = nn.Conv2d(3,96,kernel_size=11,stride=4,padding = 0)\n",
    "        self.conv2 = nn.Conv2d(96,256,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv3 = nn.Conv2d(256,384,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv4 = nn.Conv2d(384,384,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv5 = nn.Conv2d(384,256,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        #LRN\n",
    "        self.LRN = LRN(local_size=5,alpha=0.0001,beta=0.75)\n",
    "\n",
    "        #FC\n",
    "        self.fc1 = nn.Linear(256*6*6,4096)\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "        self.fc3 = nn.Linear(4096,2)\n",
    "\n",
    "        #Dropout\n",
    "        self.Dropout = nn.Dropout()#Dropout的是为了防止过拟合而设置\n",
    "        #nn.Dropout(p = 0.3) # 表示每个神经元有0.3的可能性不被激活\n",
    "\n",
    "    def forward(self,x):\n",
    "        # conv1 -> relu -> maxpool1\n",
    "        # conv1: [n, 3, 227, 227] --> [n, 96, 55, 55]\n",
    "        # maxpool1: [n, 96, 55, 55] --> [n, 96, 27, 27]\n",
    "        # print(x)\n",
    "        m = nn.MaxPool2d(3, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))#第一层卷积结果并激励\n",
    "        # print('第一个卷积层输出x shape{}'.format(x.shape))\n",
    "        x = self.LRN(x)\n",
    "        # print('第一个LRN层输出x shape{}'.format(x.shape))\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        # x = F.max_pool2d(x,(3,3),2)\n",
    "        x = m(x)\n",
    "        # print('第一个池化层输出x shape{}'.format(x.shape))\n",
    "        # x = F.max_pool2d(x,(3,3),2)\n",
    "\n",
    "        # conv2 -> relu -> maxpool2\n",
    "        # conv2: [n, 96, 27, 27] --> [n, 256, 27, 27]\n",
    "        # maxpool2: [n, 256, 27, 27] --> [n, 256, 13, 13]\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print('第二个卷积层输出x shape{}'.format(x.shape))\n",
    "        x = self.LRN(x)\n",
    "        # print('第二个LRN输出x shape{}'.format(x.shape))\n",
    "        # m = nn.MaxPool2d(3, stride=2)\n",
    "        x = m(x)\n",
    "        # print('第二个池化层输出x shape{}'.format(x.shape))\n",
    "        # x = F.max_pool2d(x,(3,3),2)\n",
    "            \n",
    "        # conv3 -> relu -> conv4 -> relu\n",
    "        # oonv3: [n, 256, 13, 13] --> [n, 384, 13, 13]\n",
    "        # conv4: [n, 384, 13, 13] --> [n, 384, 13, 13]\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print('第三个卷积层输出x shape{}'.format(x.shape))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # print('第四个卷积层输出x shape{}'.format(x.shape))\n",
    "        \n",
    "        # conv5 -> relu -> maxpool3\n",
    "        # conv5: [n. 384, 13, 13] --> [n, 256, 13, 13]\n",
    "        # maxpool3: [n, 256, 13, 13] --> [n, 256, 6, 6]\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(x, (3, 3), 2)\n",
    "            \n",
    "        # need view first for conv --> FC\n",
    "        x = x.view(x.size()[0],-1)#转换维度\n",
    "        # print('平展后输出x shape{}'.format(x.shape))\n",
    "\n",
    "        # fc1 -> fc2 -> fc3 -> softmax\n",
    "        # fc1: 256*6*6 --> 4096\n",
    "        # fc2: 4096 --> 4096\n",
    "        # fc3: 1000 --> 2\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.Dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.Dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253a25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "pre_transforms = transforms.Compose([#一组操作组合起来\n",
    "    transforms.Resize((227,227)),\n",
    "    transforms.ToTensor(),#转换类型\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700c0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self,args,mode = 'train',transform = None):\n",
    "        self.args = args\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.names = self.__dataset_info()\n",
    "    def __getitem__(self,index):#读取一个数据\n",
    "        x = cv2.imread(self.args+'/'+self.names[index],1)\n",
    "        #x 为numpy ndarry\n",
    "        x = Image.fromarray(x)#PIL\n",
    "        # array -> image\n",
    "        x_label = 0 if 'cat' in self.names[index] else 1 #贴标签\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x,x_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    def __dataset_info(self):#读取数据\n",
    "        img_path = self.args\n",
    "        imgs = [f for f in os.listdir(img_path) if\n",
    "                os.path.isfile(os.path.join(img_path,f)) and f.endswith('.jpg')]\n",
    "    #listdir 返回当前文件夹下的文件名\n",
    "    #os.path.join 将目录和文件名合并成一个路径\n",
    "    #os.path.isfile 判断是否为文件\n",
    "    #f为字符串\n",
    "        names = []\n",
    "        for name in imgs:\n",
    "            index = int(name.split('.')[1])\n",
    "            #train dataset\n",
    "            if self.mode == 'train':\n",
    "                if index >= 500:\n",
    "                    names.append(name)\n",
    "            #test dataset:1000 cat1 dog1\n",
    "            elif self.mode == 'test':\n",
    "                if index < 500:\n",
    "                    names.append(name)\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5c4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:24000 img\n"
     ]
    }
   ],
   "source": [
    "# 实例化 从训练数据中，划分训练集和验证集\n",
    "train_dataset = CatDogDataset('dogs-vs-cats/train/','train',pre_transforms)\n",
    "test_dataset = CatDogDataset('dogs-vs-cats/train/','test',pre_transforms)\n",
    "\n",
    "#print the length of train_dataset\n",
    "print('train:{} img'.format(len(train_dataset)))\n",
    "print('test:{} img'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb13aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size1 = 100\n",
    "batch_size2 = 10\n",
    "train_loader = DataLoader(train_dataset,batch_size,shuffle = True)\n",
    "test_loader = DataLoader(test_dataset,batch_size2,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0b335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet()\n",
    "#损失函数与优化方法\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alexnet.parameters(),#momentum 动量\n",
    "                lr = 0.01,momentum = 0.9,weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688264e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a109ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CPU\n"
     ]
    }
   ],
   "source": [
    "#选择加载到哪个设备上\n",
    "#选择运行在哪个设备上\n",
    "# if :\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#     print('using CPU!')\n",
    "# else:\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66377d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73ae2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_loader, model, criterion,device):\n",
    "    '''\n",
    "    Function for the validation step of the training loop\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "\n",
    "    for X, y_true in valid_loader:\n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        # Forward pass and record loss\n",
    "        y_hat = model(X)\n",
    "        y_hat = y_hat.to(device)\n",
    "        loss = criterion(y_hat, y_true)\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    return model, epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd81d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer,device):\n",
    "    '''\n",
    "    Function for the training step of the training loop\n",
    "    '''\n",
    "    model.train()\n",
    "    runnin_loss = 0\n",
    "\n",
    "    for X, y_true in train_loader:\n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward: getting the predictions for the batch using current weight\n",
    "        y_hat = model(X)\n",
    "        y_hat = y_hat.to(device)\n",
    "        # Calculate the value of the loss function\n",
    "        loss = criterion(y_hat, y_true)\n",
    "        runnin_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # Backward: The weights are adjusted based on the loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = runnin_loss / len(train_loader.dataset)\n",
    "    #每一轮训练的平均loss\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921917a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses,valid_losses):\n",
    "    plt.style.use('seaborn')\n",
    "    train_losses = np.array(train_losses)\n",
    "    valid_losses = np.array(valid_losses)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize = (8,5))\n",
    "    ax.plot(train_losses,color = 'blue',label = 'Training loss')#用默认x轴\n",
    "    ax.plot(valid_losses,color = 'red',label = 'Validation loss')\n",
    "    ax.set(title = 'Loss per epochs',xlabel = 'Epoch',ylabel = 'Loss')\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b17984f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs,device,print_every=3):\n",
    "    '''\n",
    "    Function defining the entire training loop\n",
    "    '''\n",
    "    # set objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    " \n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer,device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion,device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):            \n",
    "#             train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "                \n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "#                   f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "            print('#')\n",
    "\n",
    "    plot_losses(train_losses, valid_losses)\n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7deab361",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acdf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始训练\n",
    "model, optimizer, _ = training_loop(alexnet, criterion, optimizer, train_loader, test_loader, EPOCHS,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2d73e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4066, 0.5934])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0a0267b9d74295007041bfed4664576fc544c3c67a38063ff9d83e74a948374"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
